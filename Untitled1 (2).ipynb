{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEICkQc_JStF",
        "outputId": "a09ae93e-7740-4904-ba71-74ea69bab5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0: Loss = 0.47073804553437715\n",
            "Epoch 100: Loss = 0.3067689501668655\n",
            "Epoch 200: Loss = 0.20326689735047374\n",
            "Epoch 300: Loss = 0.1420522170051221\n",
            "Epoch 400: Loss = 0.1045056742458889\n",
            "Epoch 500: Loss = 0.08027898488420122\n",
            "Epoch 600: Loss = 0.06387909604329431\n",
            "Epoch 700: Loss = 0.05229858869654254\n",
            "Epoch 800: Loss = 0.043819524151194715\n",
            "Epoch 900: Loss = 0.03741719298315425\n",
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Sample data (text reviews and corresponding sentiments)\n",
        "# You would replace this with your dataset\n",
        "reviews = [\n",
        "    \"This movie is great!\",\n",
        "    \"The acting was superb.\",\n",
        "    \"I hated this film.\",\n",
        "    \"The plot was confusing.\",\n",
        "    \"The soundtrack was amazing.\",\n",
        "    \"This movie is terrible.\",\n",
        "    \"I loved the cinematography.\"\n",
        "]\n",
        "sentiments = [\n",
        "    1,  # Positive\n",
        "    1,  # Positive\n",
        "    0,  # Negative\n",
        "    0,  # Negative\n",
        "    1,  # Positive\n",
        "    0,  # Negative\n",
        "    1   # Positive\n",
        "]\n",
        "\n",
        "# Convert text reviews to numerical features using Bag-of-Words\n",
        "# For simplicity, we'll just count the occurrences of words\n",
        "vocab = set(word.lower() for review in reviews for word in review.split())\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "X = np.zeros((len(reviews), len(vocab)))\n",
        "for i, review in enumerate(reviews):\n",
        "    for word in review.split():\n",
        "        X[i, word_to_index[word.lower()]] += 1\n",
        "\n",
        "# Normalize the feature matrix\n",
        "X /= X.sum(axis=1, keepdims=True)\n",
        "\n",
        "# Convert sentiments to one-hot encoding\n",
        "y = np.zeros((len(sentiments), 2))\n",
        "for i, sentiment in enumerate(sentiments):\n",
        "    y[i, sentiment] = 1\n",
        "\n",
        "# Define the sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Define the derivative of the sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "# Define the neural network model\n",
        "class ANN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        self.weights_input_hidden = np.random.randn(input_size, hidden_size)\n",
        "        self.biases_input_hidden = np.zeros(hidden_size)\n",
        "        self.weights_hidden_output = np.random.randn(hidden_size, output_size)\n",
        "        self.biases_hidden_output = np.zeros(output_size)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.hidden_input = np.dot(X, self.weights_input_hidden) + self.biases_input_hidden\n",
        "        self.hidden_output = sigmoid(self.hidden_input)\n",
        "        self.output = sigmoid(np.dot(self.hidden_output, self.weights_hidden_output) + self.biases_hidden_output)\n",
        "        return self.output\n",
        "\n",
        "    def train(self, X, y, learning_rate=0.1, num_epochs=1000):\n",
        "        for epoch in range(num_epochs):\n",
        "            # Forward pass\n",
        "            self.forward(X)\n",
        "\n",
        "            # Backpropagation\n",
        "            output_error = y - self.output\n",
        "            output_delta = output_error * sigmoid_derivative(self.output)\n",
        "            hidden_error = np.dot(output_delta, self.weights_hidden_output.T)\n",
        "            hidden_delta = hidden_error * sigmoid_derivative(self.hidden_output)\n",
        "\n",
        "            # Update weights and biases\n",
        "            self.weights_hidden_output += learning_rate * np.dot(self.hidden_output.T, output_delta)\n",
        "            self.biases_hidden_output += learning_rate * np.sum(output_delta, axis=0)\n",
        "            self.weights_input_hidden += learning_rate * np.dot(X.T, hidden_delta)\n",
        "            self.biases_input_hidden += learning_rate * np.sum(hidden_delta, axis=0)\n",
        "\n",
        "            # Calculate and print the loss\n",
        "            loss = np.mean(np.abs(output_error))\n",
        "            if epoch % 100 == 0:\n",
        "                print(f'Epoch {epoch}: Loss = {loss}')\n",
        "\n",
        "# Initialize and train the model\n",
        "input_size = X.shape[1]\n",
        "hidden_size = 64\n",
        "output_size = 2  # Binary classification\n",
        "\n",
        "model = ANN(input_size, hidden_size, output_size)\n",
        "model.train(X, y)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.forward(X)\n",
        "\n",
        "# Convert predictions to binary values (0 or 1)\n",
        "binary_predictions = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = np.mean(binary_predictions == sentiments)\n",
        "print(f'Accuracy: {accuracy}')\n"
      ]
    }
  ]
}